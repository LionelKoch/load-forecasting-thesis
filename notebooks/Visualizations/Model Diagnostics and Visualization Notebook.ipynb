{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7cc0e30-6f8e-477f-83fa-2a874edb70ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️  SARIMAX Load-Only | Horizon: 24h | Anchor: 2023-03-21\n",
      "Training points: 15793, Testing points: 24\n",
      "Saved CSV: sarimax_loadonly_forecast_24h_2023-03-21.csv\n",
      "\n",
      "▶️  SARIMAX Load-Only | Horizon: 7d | Anchor: 2023-03-21\n",
      "Training points: 15793, Testing points: 168\n",
      "Saved CSV: sarimax_loadonly_forecast_7d_2023-03-21.csv\n",
      "\n",
      "▶️  SARIMAX Load-Only | Horizon: 24h | Anchor: 2023-06-21\n",
      "Training points: 18001, Testing points: 24\n",
      "Saved CSV: sarimax_loadonly_forecast_24h_2023-06-21.csv\n",
      "\n",
      "▶️  SARIMAX Load-Only | Horizon: 7d | Anchor: 2023-06-21\n",
      "Training points: 18001, Testing points: 168\n",
      "Saved CSV: sarimax_loadonly_forecast_7d_2023-06-21.csv\n",
      "\n",
      "▶️  SARIMAX Load-Only | Horizon: 24h | Anchor: 2023-12-21\n",
      "Training points: 22393, Testing points: 24\n",
      "Saved CSV: sarimax_loadonly_forecast_24h_2023-12-21.csv\n",
      "\n",
      "▶️  SARIMAX Load-Only | Horizon: 7d | Anchor: 2023-12-21\n",
      "Training points: 22393, Testing points: 168\n",
      "Saved CSV: sarimax_loadonly_forecast_7d_2023-12-21.csv\n",
      "\n",
      "✅ Saved combined results to sarimax_loadonly_summary_all_anchors.csv\n",
      "       Anchor Horizon          MAE     MAE_CI_L      MAE_CI_U          RMSE  \\\n",
      "0  2023-03-21     24h   923.923499   697.872719   1148.492029   1092.889268   \n",
      "1  2023-03-21      7d  4617.475809  3843.436167   5438.381650   7031.298699   \n",
      "2  2023-06-21     24h   877.431604   607.861164   1209.332034   1166.612681   \n",
      "3  2023-06-21      7d  4227.592172  3432.209864   5094.050761   6844.318800   \n",
      "4  2023-12-21     24h  1494.166676  1167.501044   1842.216676   1726.410220   \n",
      "5  2023-12-21      7d  9862.913584  8909.463224  10820.974859  11620.163311   \n",
      "\n",
      "      RMSE_CI_L     RMSE_CI_U      MASE  MASE_CI_L  MASE_CI_U  Runtime (s)  \n",
      "0    843.065017   1308.566666  0.231018   0.174497   0.287170     3.897622  \n",
      "1   5973.318099   7961.023130  1.154557   0.961015   1.359816     4.045992  \n",
      "2    749.860126   1595.646368  0.218798   0.151577   0.301561     3.570419  \n",
      "3   5818.537882   7881.045913  1.054199   0.855861   1.270260     3.577046  \n",
      "4   1397.959454   2073.670767  0.374483   0.292611   0.461715     4.970285  \n",
      "5  10715.362269  12486.781179  2.471943   2.232979   2.712062     5.010312  \n"
     ]
    }
   ],
   "source": [
    "##SARIMAX LOAD ONLY\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Constants ---------------------------------------------------------------\n",
    "LOAD_PATH = \"updated_load_data_with_german_holidays.csv\"\n",
    "HORIZONS = {\"24h\": 24, \"7d\": 168}\n",
    "ANCHORS = [\n",
    "    pd.Timestamp(\"2023-03-21 00:00:00\"),\n",
    "    pd.Timestamp(\"2023-06-21 00:00:00\"),\n",
    "    pd.Timestamp(\"2023-12-21 00:00:00\"),\n",
    "]\n",
    "\n",
    "# --- 1. Load data ------------------------------------------------------------\n",
    "def load_data():\n",
    "    df = (\n",
    "        pd.read_csv(LOAD_PATH, parse_dates=[\"Time\"])\n",
    "            .assign(Time=lambda d: d[\"Time\"].dt.tz_localize(None))\n",
    "            .set_index(\"Time\")\n",
    "            .asfreq(\"H\")\n",
    "            .rename(columns={\"Actual Load\": \"y\"})[[\"y\"]]\n",
    "    )\n",
    "    return df.reset_index().rename(columns={\"Time\": \"ds\"})\n",
    "\n",
    "# --- 2. Evaluation -----------------------------------------------------------\n",
    "def evaluate(y_true, y_pred, y_train):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mase_val = mase(y_true, y_pred, y_train.values, m=24)\n",
    "    return mae, rmse, mase_val\n",
    "\n",
    "def mase(y_true, y_pred, y_train, m=24):\n",
    "    \"\"\"\n",
    "    Mean Absolute Scaled Error:\n",
    "      numerator   = mean(|y_t - ŷ_t|)\n",
    "      denominator = mean(|y_t - y_{t-m}|) on the TRAINING series\n",
    "    \"\"\"\n",
    "    n = len(y_true)\n",
    "    # 1) Numerator: mean absolute forecast error on test\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    # 2) Denominator: in-sample one-step seasonal naïve errors\n",
    "    denom = np.mean(\n",
    "        np.abs(y_train[m:] - y_train[:-m])\n",
    "    )\n",
    "    return mae / denom\n",
    "\n",
    "def bootstrap_metrics(y_true, y_pred, y_train, n_boot=1000, ci=95):\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "    mae_list, rmse_list, mase_list = [], [], []\n",
    "\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.choice(len(y_true), size=len(y_true), replace=True)\n",
    "        yt, yp = y_true[idx], y_pred[idx]\n",
    "        mae_list.append(mean_absolute_error(yt, yp))\n",
    "        rmse_list.append(np.sqrt(mean_squared_error(yt, yp)))\n",
    "        # note: denominator fixed across resamples, use full y_train\n",
    "        mase_list.append(mase(yt, yp, y_train.values, m=24))\n",
    "\n",
    "    lower = (100 - ci) / 2\n",
    "    upper = 100 - lower\n",
    "    return {\n",
    "        \"MAE_CI\":  (np.percentile(mae_list, lower),   np.percentile(mae_list, upper)),\n",
    "        \"RMSE_CI\": (np.percentile(rmse_list, lower),  np.percentile(rmse_list, upper)),\n",
    "        \"MASE_CI\": (np.percentile(mase_list, lower),  np.percentile(mase_list, upper)),\n",
    "    }\n",
    "\n",
    "\n",
    "# --- 3. Main -----------------------------------------------------------------\n",
    "def main():\n",
    "    data = load_data()\n",
    "    all_results = []\n",
    "\n",
    "    for anchor in ANCHORS:\n",
    "        for label, h in HORIZONS.items():\n",
    "            print(f\"\\n▶️  SARIMAX Load-Only | Horizon: {label} | Anchor: {anchor.date()}\")\n",
    "            train_df = data[data[\"ds\"] <= anchor].copy()\n",
    "            train_df = train_df.set_index(\"ds\")\n",
    "            train_df[\"y\"] = train_df[\"y\"].interpolate(method=\"time\").fillna(method=\"bfill\")\n",
    "            train_df = train_df.reset_index()\n",
    "            test_end = anchor + timedelta(hours=h)\n",
    "            test_df  = data[(data[\"ds\"] > anchor) & (data[\"ds\"] <= test_end)].copy()\n",
    "            n_steps  = len(test_df)\n",
    "\n",
    "            print(f\"Training points: {len(train_df)}, Testing points: {n_steps}\")\n",
    "\n",
    "            # Fit SARIMAX\n",
    "            start = time.time()\n",
    "            model_fit = SARIMAX( # RENAMED variable from 'model' to 'model_fit' for clarity\n",
    "                train_df[\"y\"],\n",
    "                order=(1, 0, 1),\n",
    "                seasonal_order=(0, 1, 0, 24),\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False\n",
    "            ).fit(disp=False, maxiter=200)\n",
    "            forecast = model_fit.get_forecast(steps=n_steps).predicted_mean # Using model_fit\n",
    "            duration = time.time() - start\n",
    "\n",
    "            # NEW: Add Residual Diagnostics Plots here\n",
    "            # We'll plot residuals for each anchor and horizon for completeness\n",
    "            # You can decide to only save specific ones for your thesis if desired\n",
    "            resid = model_fit.resid.dropna() # Get residuals\n",
    "\n",
    "            fig_resid, axes_resid = plt.subplots(2, 1, figsize=(12, 8))\n",
    "            plot_acf(resid, lags=48, ax=axes_resid[0], title=f'ACF of SARIMAX (Load-Only) Residuals - {anchor.date()} {label}')\n",
    "            plot_pacf(resid, lags=48, ax=axes_resid[1], title=f'PACF of SARIMAX (Load-Only) Residuals - {anchor.date()} {label}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'sarimax_loadonly_residuals_acf_pacf_{anchor.date()}_{label}.png')\n",
    "            plt.close(fig_resid) # Close the figure to prevent it from showing up in other plots\n",
    "\n",
    "            # Evaluate\n",
    "            mask   = ~test_df[\"y\"].isna()\n",
    "            y_true = test_df.loc[mask, \"y\"].values\n",
    "            y_pred = forecast.loc[test_df.index[mask]].values\n",
    "\n",
    "            mae, rmse, mase_val = evaluate(y_true, y_pred, train_df[\"y\"])\n",
    "            ci = bootstrap_metrics(y_true, y_pred, train_df[\"y\"])\n",
    "\n",
    "            all_results.append({\n",
    "                \"Anchor\":      anchor.date(),\n",
    "                \"Horizon\":     label,\n",
    "                \"MAE\":         mae,\n",
    "                \"MAE_CI_L\":    ci[\"MAE_CI\"][0],\n",
    "                \"MAE_CI_U\":    ci[\"MAE_CI\"][1],\n",
    "                \"RMSE\":        rmse,\n",
    "                \"RMSE_CI_L\":   ci[\"RMSE_CI\"][0],\n",
    "                \"RMSE_CI_U\":   ci[\"RMSE_CI\"][1],\n",
    "                \"MASE\":        mase_val,\n",
    "                \"MASE_CI_L\":   ci[\"MASE_CI\"][0],\n",
    "                \"MASE_CI_U\":   ci[\"MASE_CI\"][1],\n",
    "                \"Runtime (s)\": duration\n",
    "            })\n",
    "\n",
    "            # Save CSV\n",
    "            export_df = pd.DataFrame({\n",
    "                \"timestamp\": test_df.loc[mask, \"ds\"].values,\n",
    "                \"actual\": y_true,\n",
    "                \"sarimax_loadonly_forecast\": y_pred\n",
    "            })\n",
    "            csv_path = f\"sarimax_loadonly_forecast_{label}_{anchor.date()}.csv\"\n",
    "            export_df.to_csv(csv_path, index=False)\n",
    "            print(f\"Saved CSV: {csv_path}\")\n",
    "\n",
    "            # Save plot\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.plot(test_df.loc[mask, \"ds\"], y_true, label=\"Actual\", lw=2)\n",
    "            plt.plot(test_df.loc[mask, \"ds\"], y_pred, label=\"Forecast\", lw=2)\n",
    "            plt.title(f\"SARIMAX Load-Only | {label} | Anchor: {anchor.date()} | MASE={mase_val:.3f}\")\n",
    "            plt.xlabel(\"Time\"); plt.ylabel(\"Load (MW)\")\n",
    "            plt.legend(); plt.grid(); plt.xticks(rotation=45); plt.tight_layout()\n",
    "            plot_path = f\"sarimax_loadonly_plot_{label}_{anchor.date()}.png\"\n",
    "            plt.savefig(plot_path)\n",
    "            plt.close() # Close the figure to free memory and prevent overlap\n",
    "            # plt.show() # Only uncomment if you want plots to pop up\n",
    "\n",
    "    # Save combined summary\n",
    "    summary_df = pd.DataFrame(all_results)\n",
    "    summary_df.to_csv(\"sarimax_loadonly_summary_all_anchors.csv\", index=False)\n",
    "    print(\"\\n✅ Saved combined results to sarimax_loadonly_summary_all_anchors.csv\")\n",
    "    print(summary_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09cecbb0-2467-4133-b0aa-d8023a87a93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️  SARIMAX+Exog | 24h | Anchor: 2023-03-21 | MASE=0.133\n",
      "Training points: 6308, Testing points: 24\n",
      "MAE  = 510.63  CI: [345.67, 676.47]\n",
      "RMSE = 648.69  CI: [448.94, 816.48]\n",
      "MASE = 0.133  CI: [0.090, 0.176]\n",
      "\n",
      "\n",
      "▶️  SARIMAX+Exog | 7d | Anchor: 2023-03-21 | MASE=0.477\n",
      "Training points: 6308, Testing points: 168\n",
      "MAE  = 1831.00  CI: [1536.71, 2116.87]\n",
      "RMSE = 2684.25  CI: [2220.92, 3115.80]\n",
      "MASE = 0.477  CI: [0.401, 0.552]\n",
      "\n",
      "\n",
      "▶️  SARIMAX+Exog | 24h | Anchor: 2023-06-21 | MASE=0.198\n",
      "Training points: 8516, Testing points: 24\n",
      "MAE  = 774.24  CI: [532.80, 1078.96]\n",
      "RMSE = 1048.17  CI: [634.20, 1475.41]\n",
      "MASE = 0.198  CI: [0.137, 0.277]\n",
      "\n",
      "\n",
      "▶️  SARIMAX+Exog | 7d | Anchor: 2023-06-21 | MASE=0.554\n",
      "Training points: 8516, Testing points: 168\n",
      "MAE  = 2162.92  CI: [1844.34, 2555.15]\n",
      "RMSE = 3156.48  CI: [2676.22, 3695.71]\n",
      "MASE = 0.554  CI: [0.473, 0.655]\n",
      "\n",
      "\n",
      "▶️  SARIMAX+Exog | 24h | Anchor: 2023-12-21 | MASE=0.531\n",
      "Training points: 12908, Testing points: 24\n",
      "MAE  = 2072.70  CI: [1724.39, 2406.05]\n",
      "RMSE = 2250.57  CI: [1939.57, 2550.78]\n",
      "MASE = 0.531  CI: [0.442, 0.616]\n",
      "\n",
      "\n",
      "▶️  SARIMAX+Exog | 7d | Anchor: 2023-12-21 | MASE=2.729\n",
      "Training points: 12908, Testing points: 168\n",
      "MAE  = 10653.45  CI: [9735.99, 11622.09]\n",
      "RMSE = 12294.18  CI: [11396.00, 13177.41]\n",
      "MASE = 2.729  CI: [2.494, 2.977]\n",
      "\n",
      "\n",
      "✅ Saved combined summary to sarimax_exog_summary_all_anchors.csv\n",
      "    Anchor Horizon          MAE    MAE_CI_L     MAE_CI_U         RMSE    RMSE_CI_L    RMSE_CI_U     MASE  MASE_CI_L  MASE_CI_U  Runtime (s)\n",
      "2023-03-21     24h   510.628930  345.672913   676.469647   648.687711   448.941102   816.476986 0.133100   0.090103   0.176328    11.480195\n",
      "2023-03-21      7d  1831.004270 1536.710541  2116.868963  2684.250969  2220.924489  3115.796373 0.477267   0.400557   0.551780    11.437734\n",
      "2023-06-21     24h   774.236394  532.804166  1078.962116  1048.170148   634.197078  1475.414118 0.198428   0.136552   0.276525     7.530931\n",
      "2023-06-21      7d  2162.919576 1844.344562  2555.150056  3156.476819  2676.216758  3695.712514 0.554331   0.472684   0.654855     7.715709\n",
      "2023-12-21     24h  2072.698995 1724.387646  2406.052524  2250.569916  1939.573546  2550.780589 0.530976   0.441747   0.616374   167.796595\n",
      "2023-12-21      7d 10653.454760 9735.986208 11622.086648 12294.183408 11395.995105 13177.406712 2.729163   2.494129   2.977304   167.934484\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Constants ---------------------------------------------------------------\n",
    "LOAD_PATH    = \"updated_load_data_with_german_holidays.csv\"\n",
    "WEATHER_PATH = \"Germany_average_temperature_humidity_2022_2024.csv\"\n",
    "HORIZONS     = {\"24h\": 24, \"7d\": 168}\n",
    "ANCHORS      = [\n",
    "    pd.Timestamp(\"2023-03-21 00:00:00\"),\n",
    "    pd.Timestamp(\"2023-06-21 00:00:00\"),\n",
    "    pd.Timestamp(\"2023-12-21 00:00:00\"),\n",
    "]\n",
    "\n",
    "# --- 1. Load & preprocess ----------------------------------------------------\n",
    "def load_data():\n",
    "    # No global interpolation—missing y's remain for SARIMAX to handle\n",
    "    ld = (\n",
    "        pd.read_csv(LOAD_PATH, parse_dates=[\"Time\"])\n",
    "            .assign(Time=lambda d: d[\"Time\"].dt.tz_localize(None))\n",
    "            .set_index(\"Time\").asfreq(\"H\")\n",
    "            .rename(columns={\"Actual Load\": \"y\"})[[\"y\"]]\n",
    "    )\n",
    "    w = (\n",
    "        pd.read_csv(WEATHER_PATH, parse_dates=[\"DateTime\"])\n",
    "            .assign(DateTime=lambda d: d[\"DateTime\"].dt.tz_localize(None))\n",
    "            .set_index(\"DateTime\").asfreq(\"H\")\n",
    "            .rename(columns={\"AverageTemperature\":\"temp_fc\",\"AverageHumidity\":\"hum_fc\"})\n",
    "    )\n",
    "    return ld.reset_index().rename(columns={\"Time\":\"ds\"}), w\n",
    "\n",
    "# --- 2. Forecast weather & add noise ----------------------------------------\n",
    "def add_realistic_weather_forecast_errors(fc_t, fc_h, h):\n",
    "    base_t, base_h = 0.8, 3.0; growth, ar = 0.15, 0.85\n",
    "    te = np.zeros(h); he = np.zeros(h)\n",
    "    for i in range(h):\n",
    "        st = base_t*(1+growth*(i/24)); sh = base_h*(1+growth*(i/24))\n",
    "        if i==0:\n",
    "            te[i] = np.random.normal(0,st); he[i] = np.random.normal(0,sh)\n",
    "        else:\n",
    "            te[i] = ar*te[i-1] + np.random.normal(0, st*np.sqrt(1-ar**2))\n",
    "            he[i] = ar*he[i-1] + np.random.normal(0, sh*np.sqrt(1-ar**2))\n",
    "    hours = np.arange(h)%24\n",
    "    diurnal = 0.4*np.sin(2*np.pi*(hours-10)/24)\n",
    "    return fc_t+te+diurnal, fc_h+he\n",
    "\n",
    "def forecast_weather(w, anchor, h):\n",
    "    order,seas = (1,0,1),(1,0,1,24)\n",
    "    wt = w[w.index<=anchor]\n",
    "    m_t = SARIMAX(wt[\"temp_fc\"], order=order, seasonal_order=seas,\n",
    "                  enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)\n",
    "    m_h = SARIMAX(wt[\"hum_fc\"], order=order, seasonal_order=seas,\n",
    "                  enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)\n",
    "    idx = pd.date_range(anchor+pd.Timedelta(hours=1),periods=h,freq=\"H\")\n",
    "    t_fc = m_t.get_forecast(h).predicted_mean.values\n",
    "    h_fc = m_h.get_forecast(h).predicted_mean.values\n",
    "    t_no, h_no = add_realistic_weather_forecast_errors(t_fc,h_fc,h)\n",
    "    df = pd.DataFrame({\"temp_fc\":t_no,\"hum_fc\":h_no}, index=idx)\n",
    "    df.index.name=\"ds\"\n",
    "    return df\n",
    "\n",
    "# --- 3. Feature engineering -------------------------------------------------\n",
    "def engineer_features(w_train, w_fc):\n",
    "    df = w_train.copy()\n",
    "    df[\"temp_diff_3h\"]   = df[\"temp_fc\"] - df[\"temp_fc\"].shift(3)\n",
    "    df[\"temp_roll_6h\"]   = df[\"temp_fc\"].rolling(6).mean()\n",
    "    df[\"hum_roll_6h\"]    = df[\"hum_fc\"].rolling(6).mean()\n",
    "    df[\"temp_x_hum\"]     = df[\"temp_fc\"]*df[\"hum_fc\"]\n",
    "    df[\"heating_demand\"] = np.clip(18-df[\"temp_fc\"],0,None)\n",
    "    df[\"cooling_demand\"] = np.clip(df[\"temp_fc\"]-18,0,None)\n",
    "    df[\"is_weekend\"]     = df.index.dayofweek.isin([5,6]).astype(int)\n",
    "    feats_train = df.dropna()\n",
    "\n",
    "    hist = w_train.rename_axis(\"ds\")\n",
    "    td,tr,hr = [],[],[]\n",
    "    for i,(_,row) in enumerate(w_fc.iterrows()):\n",
    "        prev = hist[\"temp_fc\"].iloc[-(3-i)] if i<3 else w_fc[\"temp_fc\"].iloc[i-3]\n",
    "        td.append(row[\"temp_fc\"]-prev)\n",
    "        seq_t = list(hist[\"temp_fc\"].iloc[-5:]) + list(w_fc[\"temp_fc\"].iloc[:i+1])\n",
    "        seq_h = list(hist[\"hum_fc\"].iloc[-5:])  + list(w_fc[\"hum_fc\"].iloc[:i+1])\n",
    "        tr.append(np.mean(seq_t[-6:])); hr.append(np.mean(seq_h[-6:]))\n",
    "    feats_test = w_fc.assign(\n",
    "        temp_diff_3h=td, temp_roll_6h=tr, hum_roll_6h=hr,\n",
    "        temp_x_hum=w_fc[\"temp_fc\"]*w_fc[\"hum_fc\"],\n",
    "        heating_demand=np.clip(18-w_fc[\"temp_fc\"],0,None),\n",
    "        cooling_demand=np.clip(w_fc[\"temp_fc\"]-18,0,None),\n",
    "        is_weekend=w_fc.index.dayofweek.isin([5,6]).astype(int)\n",
    "    )\n",
    "    return feats_train, feats_test\n",
    "\n",
    "def merge_and_slice(ld, feats_tr, feats_te, anchor, h):\n",
    "    # no cross-boundary interpolation here\n",
    "    feats_tr.index.name = feats_te.index.name = \"ds\"\n",
    "    all_feats = pd.concat([feats_tr, feats_te]).reset_index()\n",
    "    train_ld = ld[ld[\"ds\"]<=anchor]\n",
    "    test_ld  = ld[(ld[\"ds\"]>anchor)&(ld[\"ds\"]<=anchor+pd.Timedelta(hours=h))]\n",
    "    df_all = pd.merge(pd.concat([train_ld, test_ld]), all_feats, on=\"ds\", how=\"inner\")\n",
    "    train = df_all[df_all[\"ds\"]<=anchor]\n",
    "    test  = df_all[(df_all[\"ds\"]>anchor)&(df_all[\"ds\"]<=anchor+pd.Timedelta(hours=h))]\n",
    "    return train, test\n",
    "\n",
    "# --- 4. Error metrics (MASE) -------------------------------------------------\n",
    "def mase(y_true, y_pred, y_train, m=24):\n",
    "    num = np.mean(np.abs(y_true - y_pred))\n",
    "    den = np.mean(np.abs(y_train[m:] - y_train[:-m]))\n",
    "    return num / den\n",
    "\n",
    "def evaluate(y_true, y_pred, y_train):\n",
    "    mae     = mean_absolute_error(y_true, y_pred)\n",
    "    rmse    = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mase_val = mase(y_true, y_pred, y_train.values, m=24)\n",
    "    return mae, rmse, mase_val\n",
    "\n",
    "def bootstrap_metrics(y_true, y_pred, y_train, n_boot=1000, ci=95):\n",
    "    rng = np.random.default_rng(42)\n",
    "    mae_list, rmse_list, mase_list = [], [], []\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.choice(len(y_true), size=len(y_true), replace=True)\n",
    "        yt, yp = y_true[idx], y_pred[idx]\n",
    "        mae_list.append(mean_absolute_error(yt, yp))\n",
    "        rmse_list.append(np.sqrt(mean_squared_error(yt, yp)))\n",
    "        mase_list.append(mase(yt, yp, y_train.values, m=24))\n",
    "    lo, hi = (100-ci)/2, 100-(100-ci)/2\n",
    "    return {\n",
    "        \"MAE_CI\":  (np.percentile(mae_list, lo), np.percentile(mae_list, hi)),\n",
    "        \"RMSE_CI\": (np.percentile(rmse_list, lo), np.percentile(rmse_list, hi)),\n",
    "        \"MASE_CI\": (np.percentile(mase_list, lo), np.percentile(mase_list, hi)),\n",
    "    }\n",
    "\n",
    "# --- 5. Main loop ------------------------------------------------------------\n",
    "def main():\n",
    "    ld, w = load_data()\n",
    "    all_results = []\n",
    "\n",
    "    # Define exogenous feature names for plotting coefficients\n",
    "    exogs = [\"temp_fc\",\"hum_fc\",\"temp_diff_3h\",\"temp_roll_6h\",\n",
    "             \"hum_roll_6h\",\"temp_x_hum\",\"heating_demand\",\n",
    "             \"cooling_demand\",\"is_weekend\"]\n",
    "\n",
    "    for anchor in ANCHORS:\n",
    "        for label, h in HORIZONS.items():\n",
    "            # 1) forecast weather + engineer features + merge\n",
    "            w_fc     = forecast_weather(w, anchor, h)\n",
    "            feats_tr, feats_te = engineer_features(w[w.index<=anchor], w_fc)\n",
    "            train_df, test_df  = merge_and_slice(ld, feats_tr, feats_te, anchor, h)\n",
    "            train_df = train_df.set_index(\"ds\")\n",
    "            # interpolate the two (or fewer) missing y’s in-sample only, then back to a column\n",
    "            train_df[\"y\"] = train_df[\"y\"].interpolate(method=\"time\").fillna(method=\"bfill\")\n",
    "            train_df = train_df.reset_index()\n",
    "\n",
    "            # 2) fill exogs separately by median\n",
    "            for c in exogs:\n",
    "                med = train_df[c].median()\n",
    "                train_df[c].fillna(med, inplace=True)\n",
    "                test_df[c].fillna(med, inplace=True)\n",
    "\n",
    "            # 3) fit & forecast\n",
    "            start = time.time()\n",
    "            model_fit = SARIMAX( # RENAMED variable from 'mod' to 'model_fit' for consistency\n",
    "                train_df[\"y\"], exog=train_df[exogs],\n",
    "                order=(1,0,1), seasonal_order=(0,1,0,24),\n",
    "                enforce_stationarity=False,enforce_invertibility=False\n",
    "            ).fit(disp=False, maxiter=200)\n",
    "            fc = model_fit.get_forecast(steps=len(test_df), exog=test_df[exogs]).predicted_mean\n",
    "            runtime = time.time()-start\n",
    "\n",
    "            # NEW: Add Residual Diagnostics Plots here\n",
    "            resid = model_fit.resid.dropna()\n",
    "            fig_resid, axes_resid = plt.subplots(2, 1, figsize=(12, 8))\n",
    "            plot_acf(resid, lags=48, ax=axes_resid[0], title=f'ACF of SARIMAX (Full Exog) Residuals - {anchor.date()} {label}')\n",
    "            plot_pacf(resid, lags=48, ax=axes_resid[1], title=f'PACF of SARIMAX (Full Exog) Residuals - {anchor.date()} {label}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'sarimax_full_exog_residuals_acf_pacf_{anchor.date()}_{label}.png')\n",
    "            plt.close(fig_resid) # Close the figure to prevent it from showing up in other plots\n",
    "\n",
    "            # NEW: Add Feature Coefficient Plot (only for 24h horizon for brevity if desired, or all)\n",
    "            if label == \"24h\": # Only plot coefficients for 24h horizon to avoid redundancy\n",
    "                # Get exogenous coefficient names and values\n",
    "                # Filter param_names to only include the exogs you passed\n",
    "                exog_param_names = [p for p in model_fit.param_names if p in exogs]\n",
    "                exog_coef_values = [model_fit.params[p] for p in exog_param_names]\n",
    "\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.barh(exog_param_names, exog_coef_values, color='skyblue') # Use the filtered names and values\n",
    "                plt.xlabel(\"Coefficient Value\")\n",
    "                plt.title(f\"SARIMAX (Full Exog) Feature Coefficients - {anchor.date()} {label}\")\n",
    "                plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'sarimax_full_exog_coefficients_{anchor.date()}_{label}.png')\n",
    "                plt.close() # Close the figure\n",
    "\n",
    "            # 4) eval + CI using MASE\n",
    "            mask   = ~test_df[\"y\"].isna()\n",
    "            y_true = test_df.loc[mask, \"y\"].values\n",
    "            y_pred = fc.loc[test_df.index[mask]].values\n",
    "\n",
    "            mae, rmse, mase_val = evaluate(y_true, y_pred, train_df[\"y\"])\n",
    "            ci = bootstrap_metrics(y_true, y_pred, train_df[\"y\"])\n",
    "            \n",
    "            print(f\"\\n▶️  SARIMAX+Exog | {label} | Anchor: {anchor.date()} | \"\n",
    "                f\"MASE={mase_val:.3f}\")\n",
    "            print(f\"Training points: {len(train_df)}, Testing points: {len(test_df)}\")\n",
    "            print(f\"MAE  = {mae:.2f}  CI: [{ci['MAE_CI'][0]:.2f}, {ci['MAE_CI'][1]:.2f}]\")\n",
    "            print(f\"RMSE = {rmse:.2f}  CI: [{ci['RMSE_CI'][0]:.2f}, {ci['RMSE_CI'][1]:.2f}]\")\n",
    "            print(f\"MASE = {mase_val:.3f}  CI: [{ci['MASE_CI'][0]:.3f}, {ci['MASE_CI'][1]:.3f}]\\n\")\n",
    "\n",
    "            all_results.append({\n",
    "                \"Anchor\":    anchor.date(),\n",
    "                \"Horizon\":   label,\n",
    "                \"MAE\":       mae,\n",
    "                \"MAE_CI_L\":  ci[\"MAE_CI\"][0],\"MAE_CI_U\": ci[\"MAE_CI\"][1],\n",
    "                \"RMSE\":      rmse,\n",
    "                \"RMSE_CI_L\": ci[\"RMSE_CI\"][0],\"RMSE_CI_U\":ci[\"RMSE_CI\"][1],\n",
    "                \"MASE\":      mase_val,\n",
    "                \"MASE_CI_L\": ci[\"MASE_CI\"][0],\"MASE_CI_U\":ci[\"MASE_CI\"][1],\n",
    "                \"Runtime (s)\": runtime\n",
    "            })\n",
    "\n",
    "            # 5) output & plot with MASE title\n",
    "            out_df = pd.DataFrame({\n",
    "                \"timestamp\": test_df.loc[mask, \"ds\"],\n",
    "                \"actual\":    y_true,\n",
    "                \"forecast\":  y_pred\n",
    "            })\n",
    "            out_df.to_csv(f\"sarimax_exog_forecast_{label}_{anchor.date()}.csv\", index=False)\n",
    "\n",
    "            plt.figure(figsize=(10,4))\n",
    "            plt.plot(out_df[\"timestamp\"], out_df[\"actual\"], label=\"Actual\", lw=2)\n",
    "            plt.plot(out_df[\"timestamp\"], out_df[\"forecast\"], label=\"Forecast\", lw=2)\n",
    "            plt.title(f\"SARIMAX+Exog | {label} | {anchor.date()} | MASE={mase_val:.3f}\")\n",
    "            plt.xticks(rotation=45); plt.grid(True); plt.legend(); plt.tight_layout()\n",
    "            plt.savefig(f\"sarimax_exog_plot_{label}_{anchor.date()}.png\")\n",
    "            plt.close() # Close the figure\n",
    "            # plt.show() # Only uncomment if you want plots to pop up\n",
    "\n",
    "    summary = pd.DataFrame(all_results)\n",
    "    summary.to_csv(\"sarimax_exog_summary_all_anchors.csv\", index=False)\n",
    "    # force pandas to dump the entire DataFrame\n",
    "    print(\"\\n✅ Saved combined summary to sarimax_exog_summary_all_anchors.csv\")\n",
    "    print(summary.to_string(index=False))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69ea3b58-4516-4a59-ad47-db6ca6076b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Figure 4.3 saved as 'Figure_4_3_SARIMAX_Residuals_Combined.png'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image # Make sure you have the Pillow library installed (pip install Pillow)\n",
    "import os\n",
    "\n",
    "# --- Define paths to your individual ACF/PACF image files ---\n",
    "# IMPORTANT: Ensure these filenames exactly match what's in your directory\n",
    "# and that they are in the same directory as this script, or provide full paths.\n",
    "\n",
    "# Panel (a): SARIMAX Load-Only, 24h\n",
    "path_a = 'sarimax_loadonly_residuals_acf_pacf_2023-12-21_24h.png'\n",
    "# Panel (b): SARIMAX Load-Only, 7d\n",
    "path_b = 'sarimax_loadonly_residuals_acf_pacf_2023-12-21_7d.png' # CONFIRM YOU HAVE THIS FILE!\n",
    "# Panel (c): SARIMAX Full Exog, 24h\n",
    "path_c = 'sarimax_full_exog_residuals_acf_pacf_2023-12-21_24h.png'\n",
    "# Panel (d): SARIMAX Full Exog, 7d\n",
    "path_d = 'sarimax_full_exog_residuals_acf_pacf_2023-12-21_7d.png'\n",
    "\n",
    "# --- Verify files exist before attempting to load ---\n",
    "for p in [path_a, path_b, path_c, path_d]:\n",
    "    if not os.path.exists(p):\n",
    "        print(f\"Error: File not found - {p}\")\n",
    "        print(\"Please ensure all four required PNG files are in the same directory as this script.\")\n",
    "        print(\"If 'sarimax_loadonly_residuals_acf_pacf_2023-12-21_7d.png' is missing, please run your 'SARIMAX LOAD ONLY' script again.\")\n",
    "        exit() # Exit if a file is missing\n",
    "\n",
    "# --- Load the images ---\n",
    "img_a = Image.open(path_a)\n",
    "img_b = Image.open(path_b)\n",
    "img_c = Image.open(path_c)\n",
    "img_d = Image.open(path_d)\n",
    "\n",
    "# --- Create a figure with 2 rows and 2 columns for 4 subplots ---\n",
    "# Adjust figsize as needed. A larger figure will make the subplots clearer.\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10)) # Adjust figsize as needed\n",
    "\n",
    "# --- Display each image in its respective subplot ---\n",
    "# Row 0, Column 0 (top-left)\n",
    "axes[0, 0].imshow(img_a)\n",
    "axes[0, 0].set_title('(a) SARIMAX (Load-Only) - 24h Forecast')\n",
    "axes[0, 0].axis('off') # Hide axes ticks and labels for the image\n",
    "\n",
    "# Row 0, Column 1 (top-right)\n",
    "axes[0, 1].imshow(img_b)\n",
    "axes[0, 1].set_title('(b) SARIMAX (Load-Only) - 7d Forecast')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Row 1, Column 0 (bottom-left)\n",
    "axes[1, 0].imshow(img_c)\n",
    "axes[1, 0].set_title('(c) SARIMAX (Full Exog) - 24h Forecast')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# Row 1, Column 1 (bottom-right)\n",
    "axes[1, 1].imshow(img_d)\n",
    "axes[1, 1].set_title('(d) SARIMAX (Full Exog) - 7d Forecast')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "# --- Add a single overall title for the entire figure ---\n",
    "fig.suptitle('ACF and PACF of SARIMAX Residuals - Winter Anchor (December 21, 2023)', y=1.02, fontsize=16)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.98]) # Adjust layout to make space for suptitle\n",
    "plt.savefig('Figure_4_3_SARIMAX_Residuals_Combined.png', dpi=300, bbox_inches='tight') # Save the combined figure\n",
    "plt.close(fig) # Close the figure to free up memory\n",
    "\n",
    "print(\"Combined Figure 4.3 saved as 'Figure_4_3_SARIMAX_Residuals_Combined.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ad1d7a-c790-433b-b8b5-cfb6d3cacb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting TimeGPT Residuals Analysis ---\n",
      "\n",
      "Analyzing residuals for: TimeGPT_LoadOnly_Winter_24h\n",
      "Saved timegpt_loadonly_winter_24h_acf_pacf.png\n",
      "Saved timegpt_loadonly_winter_24h_distribution.png\n",
      "\n",
      "Analyzing residuals for: TimeGPT_LoadOnly_Winter_7d\n",
      "Saved timegpt_loadonly_winter_7d_acf_pacf.png\n",
      "Saved timegpt_loadonly_winter_7d_distribution.png\n",
      "\n",
      "Analyzing residuals for: TimeGPT_LoadOnly_Summer_24h\n",
      "Saved timegpt_loadonly_summer_24h_acf_pacf.png\n",
      "Saved timegpt_loadonly_summer_24h_distribution.png\n",
      "\n",
      "Analyzing residuals for: TimeGPT_LoadOnly_Summer_7d\n",
      "Saved timegpt_loadonly_summer_7d_acf_pacf.png\n",
      "Saved timegpt_loadonly_summer_7d_distribution.png\n",
      "\n",
      "Analyzing residuals for: TimeGPT_FullExog_Winter_24h\n",
      "Saved timegpt_fullexog_winter_24h_acf_pacf.png\n",
      "Saved timegpt_fullexog_winter_24h_distribution.png\n",
      "\n",
      "Analyzing residuals for: TimeGPT_FullExog_Winter_7d\n",
      "Saved timegpt_fullexog_winter_7d_acf_pacf.png\n",
      "Saved timegpt_fullexog_winter_7d_distribution.png\n",
      "\n",
      "Analyzing residuals for: TimeGPT_FullExog_Summer_24h\n",
      "Saved timegpt_fullexog_summer_24h_acf_pacf.png\n",
      "Saved timegpt_fullexog_summer_24h_distribution.png\n",
      "\n",
      "Analyzing residuals for: TimeGPT_FullExog_Summer_7d\n",
      "Saved timegpt_fullexog_summer_7d_acf_pacf.png\n",
      "Saved timegpt_fullexog_summer_7d_distribution.png\n",
      "\n",
      "--- TimeGPT Residuals Analysis Complete ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "FORECAST_CSVS = {\n",
    "    # TimeGPT Load-Only\n",
    "    \"TimeGPT_LoadOnly_Winter_24h\": \"timegpt_loadonly_24h_2023-12-21.csv\",\n",
    "    \"TimeGPT_LoadOnly_Winter_7d\":  \"timegpt_loadonly_7d_2023-12-21.csv\",\n",
    "    \"TimeGPT_LoadOnly_Summer_24h\": \"timegpt_loadonly_24h_2023-06-21.csv\",\n",
    "    \"TimeGPT_LoadOnly_Summer_7d\":  \"timegpt_loadonly_7d_2023-06-21.csv\",\n",
    "    \n",
    "    # TimeGPT Full Exog (your scripts save these as 'load+exog')\n",
    "    \"TimeGPT_FullExog_Winter_24h\": \"timegpt_load+exog_24h_2023-12-21.csv\",\n",
    "    \"TimeGPT_FullExog_Winter_7d\":  \"timegpt_load+exog_7d_2023-12-21.csv\",\n",
    "    \"TimeGPT_FullExog_Summer_24h\": \"timegpt_load+exog_24h_2023-06-21.csv\",\n",
    "    \"TimeGPT_FullExog_Summer_7d\":  \"timegpt_load+exog_7d_2023-06-21.csv\",\n",
    "}\n",
    "\n",
    "OUTPUT_DIR = \"timegpt_residual_plots\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# --- Plotting Functions ---\n",
    "def plot_residuals_acf_pacf(residuals, title_suffix, filename_prefix):\n",
    "    \"\"\"Generates and saves ACF/PACF plots for given residuals.\"\"\"\n",
    "    valid_residuals = residuals.dropna()\n",
    "\n",
    "    if valid_residuals.empty:\n",
    "        print(f\"Warning: No valid residuals to plot ACF/PACF for {title_suffix}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Determine appropriate lags:\n",
    "    # Max lags should be less than the number of valid_residuals points for ACF.\n",
    "    # For PACF, it has a stricter limit of less than half the sample size.\n",
    "    # We choose the more restrictive limit to avoid errors.\n",
    "    \n",
    "    # General rule of thumb for PACF: nlags < n_samples / 2\n",
    "    # So, max_lags should be at most (len(valid_residuals) // 2) - 1\n",
    "    \n",
    "    # Let's target a max of 48 for longer series, but respect PACF's limit\n",
    "    # The smallest number of samples is 24 (for 24h forecast). 24 // 2 - 1 = 12 - 1 = 11.\n",
    "    \n",
    "    # So, for 24h series, lags should be at most 11.\n",
    "    # For 7d series (168 samples), 168 // 2 - 1 = 84 - 1 = 83.\n",
    "    # Let's cap the overall max_lags at 48 for plots, but use the dynamic calculation\n",
    "    \n",
    "    max_lags = min(48, (len(valid_residuals) // 2) - 1)\n",
    "\n",
    "    if max_lags <= 0:\n",
    "        print(f\"Warning: Not enough data points ({len(valid_residuals)}) to plot meaningful ACF/PACF for {title_suffix} (max_lags={max_lags}). Skipping.\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "    plot_acf(valid_residuals, lags=max_lags, ax=axes[0], title=f'ACF of TimeGPT Residuals - {title_suffix}')\n",
    "    plot_pacf(valid_residuals, lags=max_lags, ax=axes[1], title=f'PACF of TimeGPT Residuals - {title_suffix}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f'{filename_prefix}_acf_pacf.png'))\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved {filename_prefix}_acf_pacf.png\")\n",
    "\n",
    "def plot_residuals_distribution(residuals, title_suffix, filename_prefix):\n",
    "    \"\"\"Generates and saves a distribution plot (histogram/KDE) for given residuals.\"\"\"\n",
    "    if residuals.empty or residuals.isnull().all():\n",
    "        print(f\"Warning: No valid residuals to plot distribution for {title_suffix}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(residuals.dropna(), kde=True, bins=30, stat=\"density\", color='teal')\n",
    "    plt.title(f'Distribution of TimeGPT Residuals - {title_suffix}')\n",
    "    plt.xlabel('Residual Value (MW)')\n",
    "    plt.ylabel('Density')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f'{filename_prefix}_distribution.png'))\n",
    "    plt.close()\n",
    "    print(f\"Saved {filename_prefix}_distribution.png\")\n",
    "\n",
    "# --- Main Processing ---\n",
    "def analyze_timegpt_residuals():\n",
    "    print(\"--- Starting TimeGPT Residuals Analysis ---\")\n",
    "    for scenario_name, csv_path in FORECAST_CSVS.items():\n",
    "        if not os.path.exists(csv_path):\n",
    "            print(f\"Error: CSV file not found for {scenario_name}: {csv_path}. Skipping.\")\n",
    "            print(\"Please ensure you have run your TimeGPT forecasting scripts to generate these files.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nAnalyzing residuals for: {scenario_name}\")\n",
    "        df_forecast = pd.read_csv(csv_path, parse_dates=['timestamp'])\n",
    "        \n",
    "        combined_df = df_forecast[['timestamp', 'actual', 'forecast']].set_index('timestamp')\n",
    "        combined_df.dropna(subset=['actual', 'forecast'], inplace=True) \n",
    "        \n",
    "        residuals = combined_df['actual'] - combined_df['forecast']\n",
    "\n",
    "        # Plot ACF/PACF\n",
    "        plot_residuals_acf_pacf(residuals, scenario_name, scenario_name.lower().replace(\" \", \"_\"))\n",
    "\n",
    "        # Plot Residual Distribution\n",
    "        plot_residuals_distribution(residuals, scenario_name, scenario_name.lower().replace(\" \", \"_\"))\n",
    "    print(\"\\n--- TimeGPT Residuals Analysis Complete ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_timegpt_residuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee6d2df4-7341-4c63-bc1f-a3e6bcdc05db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Figure 4.4 saved as 'Figure_4_4_TimeGPT_Residuals_Distributions_Combined.png'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image # Make sure you have the Pillow library installed (pip install Pillow)\n",
    "import os\n",
    "\n",
    "# --- Define paths to your individual TimeGPT residual distribution image files ---\n",
    "# IMPORTANT: These filenames are adjusted to match your screenshot (no date in filename)\n",
    "output_sub_dir = \"timegpt_residual_plots\" # The directory where your individual plots are saved\n",
    "\n",
    "# Panel (a): TimeGPT Load-Only, Winter 24h Distribution\n",
    "# Based on your screenshot, this would be: timegpt_loadonly_winter_24h_distribution.png\n",
    "path_a = os.path.join(output_sub_dir, 'timegpt_loadonly_winter_24h_distribution.png')\n",
    "\n",
    "# Panel (b): TimeGPT Full Exog, Summer 24h Distribution\n",
    "# Based on your screenshot, this would be: timegpt_fullexog_summer_24h_distribution.png\n",
    "path_b = os.path.join(output_sub_dir, 'timegpt_fullexog_summer_24h_distribution.png')\n",
    "\n",
    "# Panel (c): TimeGPT Full Exog, Winter 24h Distribution\n",
    "# Based on your screenshot, this would be: timegpt_fullexog_winter_24h_distribution.png\n",
    "path_c = os.path.join(output_sub_dir, 'timegpt_fullexog_winter_24h_distribution.png')\n",
    "\n",
    "\n",
    "# --- Verify files exist before attempting to load ---\n",
    "for p in [path_a, path_b, path_c]:\n",
    "    if not os.path.exists(p):\n",
    "        print(f\"Error: File not found - {p}\")\n",
    "        print(\"Please ensure all three required PNG files are in the specified 'timegpt_residual_plots' directory.\")\n",
    "        exit() # Exit if a file is missing\n",
    "\n",
    "# --- Load the images ---\n",
    "img_a = Image.open(path_a)\n",
    "img_b = Image.open(path_b)\n",
    "img_c = Image.open(path_c)\n",
    "\n",
    "# --- Create a figure with 3 rows and 1 column for 3 subplots ---\n",
    "# Adjust figsize as needed to make sure plots are clear and not squished\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15)) # You might need to experiment with figsize\n",
    "\n",
    "# --- Display each image in its respective subplot ---\n",
    "axes[0].imshow(img_a)\n",
    "axes[0].set_title('(a) TimeGPT (Load-Only) - Winter 24h Forecast')\n",
    "axes[0].axis('off') # Hide axes ticks and labels for the image\n",
    "\n",
    "axes[1].imshow(img_b)\n",
    "axes[1].set_title('(b) TimeGPT (Full Exog) - Summer 24h Forecast')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(img_c)\n",
    "axes[2].set_title('(c) TimeGPT (Full Exog) - Winter 24h Forecast')\n",
    "axes[2].axis('off')\n",
    "\n",
    "# --- Add a single overall title for the entire figure ---\n",
    "fig.suptitle('Distribution of TimeGPT Residuals - Key Scenarios', y=1.02, fontsize=16)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.98]) # Adjust layout to make space for suptitle\n",
    "plt.savefig('Figure_4_4_TimeGPT_Residuals_Distributions_Combined.png', dpi=300, bbox_inches='tight') # Save the combined figure\n",
    "plt.close(fig) # Close the figure to free up memory\n",
    "\n",
    "print(\"Combined Figure 4.4 saved as 'Figure_4_4_TimeGPT_Residuals_Distributions_Combined.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd43dbb-586e-4d8f-95d2-c8abcb042085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd3b7d2-a21c-4868-98dc-d2fcf67f3c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
